{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFvFhIaGuZjc",
        "outputId": "21bab94f-b936-4084-8d5b-4acebc741919"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mlds6/MLDS6_Proyecto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "!ls\n",
        "# Load data\n",
        "data = pd.read_json('../../src/bazinga/database/Clean_Headlines.json', lines=True)\n",
        "headlines = data['headline']\n",
        "labels = data['is_sarcastic']\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Pt_H7lsqkT",
        "outputId": "4ebe5581-2361-437a-f761-a97942434fef"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_embeddings.csv  bert_embeddings.npy  main.py\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26709 entries, 0 to 26708\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   article_link  26709 non-null  object\n",
            " 1   headline      26709 non-null  object\n",
            " 2   is_sarcastic  26709 non-null  int64 \n",
            " 3   clean_text    26709 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 834.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tatk4KwAJCq",
        "outputId": "c2d020ca-b557-4598-fa7d-abf3db01120d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "def get_bert_embeddings(texts, batch_size=32):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # Use [CLS] token and move back to CPU\n",
        "        embeddings.append(batch_embeddings)\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "bert_embeddings = get_bert_embeddings(headlines.tolist())"
      ],
      "metadata": {
        "id": "cJabzgxY0-R8"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save BERT embeddings to file\n",
        "np.save('bert_embeddings.npy', bert_embeddings)\n",
        "bert_df = pd.DataFrame(bert_embeddings)\n",
        "bert_df.to_csv('bert_embeddings.csv', index=False)\n",
        "\n",
        "# Load BERT embeddings from file\n",
        "loaded_bert_embeddings = np.load('bert_embeddings.npy')\n",
        "loaded_bert_df = pd.read_csv('bert_embeddings.csv')\n",
        "loaded_bert_embeddings_from_csv = loaded_bert_df.to_numpy()"
      ],
      "metadata": {
        "id": "T66tIf4w7f4k"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bert_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC9_TNur1UzW",
        "outputId": "1bfc69ce-03b1-45d9-85b6-3a5ee3f14b4e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.2787512   0.1250676  -0.43515998 ... -0.2610952   0.18953992\n",
            "   0.30300787]\n",
            " [ 0.2868716   0.19836088  0.06834832 ... -0.26255423  0.18669052\n",
            "   0.46911144]\n",
            " [-0.5403207  -0.23035818  0.47407225 ... -0.44920158  0.3639957\n",
            "   0.01749162]\n",
            " ...\n",
            " [-0.25932276 -0.09551144 -0.61754864 ... -0.05595682  0.46902227\n",
            "   0.20649998]\n",
            " [-0.09609814  0.23278977 -0.24334513 ... -0.4787058  -0.01567005\n",
            "   0.11095161]\n",
            " [-0.25170836  0.01995322  0.24349986 ... -0.31329057 -0.02248631\n",
            "   0.3239032 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the headlines\n",
        "tokenized_headlines = [headline.split() for headline in headlines]\n",
        "\n",
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(sentences=tokenized_headlines, vector_size=300, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Generate Word2Vec embeddings\n",
        "def get_w2v_embeddings(texts, model):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        words = text.split()\n",
        "        word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "        if word_vectors:\n",
        "            embeddings.append(np.mean(word_vectors, axis=0))\n",
        "        else:\n",
        "            embeddings.append(np.zeros(300))  # Handle empty cases\n",
        "    return np.array(embeddings)\n",
        "\n",
        "w2v_embeddings = get_w2v_embeddings(headlines, w2v_model)"
      ],
      "metadata": {
        "id": "vs4dTHKNrJj6"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Word2Vec embeddings\n",
        "np.save('w2v_embeddings.npy', w2v_embeddings)\n",
        "w2v_df = pd.DataFrame(w2v_embeddings)\n",
        "\n",
        "# Save to CSV\n",
        "w2v_df.to_csv('w2v_embeddings.csv', index=False)\n",
        "loaded_w2v_embeddings = np.load('w2v_embeddings.npy')\n",
        "loaded_w2v_df = pd.read_csv('w2v_embeddings.csv')\n",
        "loaded_w2v_embeddings = loaded_w2v_df.to_numpy()"
      ],
      "metadata": {
        "id": "svEHaJ9DBK21"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w2v_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5788skmz84F",
        "outputId": "8ea278d6-271e-4e1e-9e9b-11018565c789"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.0041957   0.22404993  0.09574366 ... -0.13403803  0.20319869\n",
            "  -0.06994065]\n",
            " [-0.01266595  0.39859638  0.17234276 ... -0.21259151  0.34799477\n",
            "  -0.12914315]\n",
            " [-0.01191726  0.39524963  0.17347732 ... -0.18527654  0.3363047\n",
            "  -0.13570245]\n",
            " ...\n",
            " [-0.01523993  0.49155304  0.20881777 ... -0.27298486  0.4282649\n",
            "  -0.15189879]\n",
            " [-0.00379999  0.09126084  0.03992998 ... -0.05554602  0.0829154\n",
            "  -0.02970187]\n",
            " [-0.00941545  0.31437373  0.13352586 ... -0.1776877   0.2778742\n",
            "  -0.09951697]]\n"
          ]
        }
      ]
    }
  ]
}