{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFvFhIaGuZjc",
        "outputId": "21bab94f-b936-4084-8d5b-4acebc741919"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Pt_H7lsqkT",
        "outputId": "4ebe5581-2361-437a-f761-a97942434fef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\envs\\GPU_Py_12_3_ML\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26709 entries, 0 to 26708\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   article_link  26709 non-null  object\n",
            " 1   headline      26709 non-null  object\n",
            " 2   is_sarcastic  26709 non-null  int64 \n",
            " 3   clean_text    26709 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 834.8+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "!ls\n",
        "# Load data\n",
        "data = pd.read_json('../../src/bazinga/database/Clean_Headlines.json', lines=True)\n",
        "headlines = data['headline']\n",
        "labels = data['is_sarcastic']\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tatk4KwAJCq",
        "outputId": "c2d020ca-b557-4598-fa7d-abf3db01120d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cJabzgxY0-R8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\envs\\GPU_Py_12_3_ML\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "def get_bert_embeddings(texts, batch_size=32):\n",
        "    \n",
        "   \n",
        "\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # Use [CLS] token and move back to CPU\n",
        "        embeddings.append(batch_embeddings)\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "bert_embeddings = get_bert_embeddings(headlines.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T66tIf4w7f4k"
      },
      "outputs": [],
      "source": [
        "# Save BERT embeddings to file\n",
        "np.save('bert_embeddings.npy', bert_embeddings)\n",
        "bert_df = pd.DataFrame(bert_embeddings)\n",
        "bert_df.to_csv('bert_embeddings.csv', index=False)\n",
        "\n",
        "# Load BERT embeddings from file\n",
        "loaded_bert_embeddings = np.load('bert_embeddings.npy')\n",
        "loaded_bert_df = pd.read_csv('bert_embeddings.csv')\n",
        "loaded_bert_embeddings_from_csv = loaded_bert_df.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC9_TNur1UzW",
        "outputId": "1bfc69ce-03b1-45d9-85b6-3a5ee3f14b4e"
      },
      "outputs": [],
      "source": [
        "print(bert_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs4dTHKNrJj6"
      },
      "outputs": [],
      "source": [
        "# Tokenize the headlines\n",
        "tokenized_headlines = [headline.split() for headline in headlines]\n",
        "\n",
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(sentences=tokenized_headlines, vector_size=300, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Generate Word2Vec embeddings\n",
        "def get_w2v_embeddings(texts, model):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        words = text.split()\n",
        "        word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "        if word_vectors:\n",
        "            embeddings.append(np.mean(word_vectors, axis=0))\n",
        "        else:\n",
        "            embeddings.append(np.zeros(300))  # Handle empty cases\n",
        "    return np.array(embeddings)\n",
        "\n",
        "w2v_embeddings = get_w2v_embeddings(headlines, w2v_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svEHaJ9DBK21"
      },
      "outputs": [],
      "source": [
        "# Save Word2Vec embeddings\n",
        "np.save('w2v_embeddings.npy', w2v_embeddings)\n",
        "w2v_df = pd.DataFrame(w2v_embeddings)\n",
        "\n",
        "# Save to CSV\n",
        "w2v_df.to_csv('w2v_embeddings.csv', index=False)\n",
        "loaded_w2v_embeddings = np.load('w2v_embeddings.npy')\n",
        "loaded_w2v_df = pd.read_csv('w2v_embeddings.csv')\n",
        "loaded_w2v_embeddings = loaded_w2v_df.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5788skmz84F",
        "outputId": "8ea278d6-271e-4e1e-9e9b-11018565c789"
      },
      "outputs": [],
      "source": [
        "print(w2v_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
